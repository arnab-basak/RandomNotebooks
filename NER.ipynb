{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves= dataiku.Folder(\"saves\")\n",
    "saves_info = saves.get_info()\n",
    "saves_path=saves_info['path']+'/base_config.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path=saves_info['path']+'/config.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/apps/dataiku/dss_data/managed_folders/DUMMY/AxgEatK8/base_config.cfg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saves_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/apps/dataiku/dss_data/managed_folders/DUMMY/AxgEatK8/config.cfg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/apps/dataiku/dss_data/managed_folders/DUMMY/AxgEatK8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saves_info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: spacy\n",
      "Version: 3.6.1\n",
      "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
      "Home-page: https://spacy.io\n",
      "Author: Explosion\n",
      "Author-email: contact@explosion.ai\n",
      "License: MIT\n",
      "Location: /apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages\n",
      "Requires: catalogue, cymem, jinja2, langcodes, murmurhash, numpy, packaging, pathy, preshed, pydantic, requests, setuptools, smart-open, spacy-legacy, spacy-loggers, srsly, thinc, tqdm, typer, typing-extensions, wasabi\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "db = DocBin() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRAIN_DATA=[('The F15 aircraft uses a lot of fuel', {'entities': [(4, 7, 'aircraft')]}),\n",
    " ('did you see the F16 landing?', {'entities': [(16, 19, 'aircraft')]}),\n",
    " ('how many missiles can a F35 carry', {'entities': [(24, 27, 'aircraft')]}),\n",
    " ('is the F15 outdated', {'entities': [(7, 10, 'aircraft')]}),\n",
    " ('does the US still train pilots to dog fight?',\n",
    "  {'entities': [(0, 0, 'aircraft')]}),\n",
    " ('how long does it take to train a F16 pilot',\n",
    "  {'entities': [(33, 36, 'aircraft')]}),\n",
    " ('how much does a F35 cost', {'entities': [(16, 19, 'aircraft')]}),\n",
    " ('would it be possible to steal a F15', {'entities': [(32, 35, 'aircraft')]}),\n",
    " ('who manufactures the F16', {'entities': [(21, 24, 'aircraft')]}),\n",
    " ('how many countries have bought the F35',\n",
    "  {'entities': [(35, 38, 'aircraft')]}),\n",
    " ('is the F35 a waste of money', {'entities': [(7, 10, 'aircraft')]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test='Show me last 3 months sale of product xyz as bar chart.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product xyz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[30:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last 3 months'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[8:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bar chart'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[45:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA=[(\"provide me product xyz orders in last 3 months in bar chart format \\r\",{\"entities\":[[11,22,\"PRODUCT\"],\n",
    "[33,46,\"TIME\"],\n",
    "[50,59,\"CHART\"]]}),\n",
    "(\"Show me last 4 months sale of product pqr as bar chart.\\r\",{\"entities\":[[8,21,\"TIME\"],\n",
    "[30,41,\"CHART\"],\n",
    "[45,54,\"CHART\"]]}),\n",
    "(\"give product abc sales for last 8 months in bar chart\\r\",{\"entities\":[[5,16,\"PRODUCT\"],\n",
    "[27,40,\"TIME\"],\n",
    "[44,53,\"CHART\"]]}),\n",
    "(\"get me in bar chart last 10 monthes of sales for product omc\\r\",{\"entities\":[[10,19,\"CHART\"],\n",
    "[20,35,\"TIME\"],\n",
    "[49,60,\"PRODUCT\"]]}),\n",
    "(\"present me last 2 months of revenue in pie chart for product zzk\\r\",{\"entities\":[[11,24,\"TIME\"],\n",
    "[39,48,\"CHART\"],\n",
    "[53,64,\"PRODUCT\"]]}),\n",
    "(\"show me in violin chart the last 22 months of expenditure for product ppz\\r\",{\"entities\":[[11,23,\"CHART\"],\n",
    "[28,42,\"TIME\"],\n",
    "[62,73,\"PRODUCT\"]]}),\n",
    "(\"provide for product lmp in pie chart last 6 months of sales\\r\",{\"entities\":[[12,23,\"PRODUCT\"],\n",
    "[27,36,\"CHART\"],\n",
    "[37,50,\"TIME\"]]}),\n",
    "(\"get me product lmno sales for last 18 months in violin chart\\r\",{\"entities\":[[7,19,\"PRODUCT\"],\n",
    "[30,44,\"TIME\"],\n",
    "[48,60,\"CHART\"]]}),\n",
    "(\"In bar chart show me last 7 months of loss for product ppr.\\r\",{\"entities\":[[3,12,\"CHART\"],\n",
    "[21,34,\"TIME\"],\n",
    "[47,58,\"PRODUCT\"]]}),\n",
    "(\"For last 56 months get me in pie chart sales of product aab\",{\"entities\":[[4,18,\"TIME\"],\n",
    "[29,38,\"CHART\"],\n",
    "[48,59,\"PRODUCT\"]]})]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for text, annot in TRAIN_DATA: # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            pass\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path=saves_info['path']+'/train.spacy'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "db.to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "output_dir=saves_info['path']\n",
    "n_iter=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank 'en' model\")\n",
    "\n",
    "#set up the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    #ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe('ner', last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/language.py:1060: DeprecationWarning: [W096] The method `nlp.disable_pipes` is now deprecated - use `nlp.select_pipes` instead.\n",
      "  warnings.warn(Warnings.W096, DeprecationWarning)\n",
      "/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/language.py:1279: DeprecationWarning: [W089] As of spaCy v3.0, the `nlp.begin_training` method has been renamed to `nlp.initialize`.\n",
      "  warnings.warn(Warnings.W089, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 48.69428062438965}\n",
      "{'ner': 94.18872714042664}\n",
      "{'ner': 113.44986003637314}\n",
      "{'ner': 31.537646740674973}\n",
      "{'ner': 54.407584719359875}\n",
      "{'ner': 63.5409092027694}\n",
      "{'ner': 17.220817839261144}\n",
      "{'ner': 32.318819880516}\n",
      "{'ner': 38.864241727294484}\n",
      "{'ner': 26.28723132026039}\n",
      "{'ner': 82.13920145772113}\n",
      "{'ner': 103.95781522106677}\n",
      "{'ner': 28.72135057102423}\n",
      "{'ner': 56.19570752850268}\n",
      "{'ner': 67.30738716537599}\n",
      "{'ner': 20.437580887111835}\n",
      "{'ner': 40.348902545665624}\n",
      "{'ner': 48.051459858910675}\n",
      "{'ner': 15.562030771845457}\n",
      "{'ner': 24.59902745463296}\n",
      "{'ner': 28.398789211649394}\n",
      "{'ner': 6.7218087246859}\n",
      "{'ner': 11.130971840118818}\n",
      "{'ner': 11.771853810591502}\n",
      "{'ner': 1.4514382282813862}\n",
      "{'ner': 6.093078789296131}\n",
      "{'ner': 7.918983608043928}\n",
      "{'ner': 2.909089909616881}\n",
      "{'ner': 7.019620747849132}\n",
      "{'ner': 8.323473524633414}\n",
      "{'ner': 0.016159948286468745}\n",
      "{'ner': 2.0186607484219654}\n",
      "{'ner': 2.0390488855665203}\n",
      "{'ner': 0.010336379984821547}\n",
      "{'ner': 0.8741607160762073}\n",
      "{'ner': 0.896305416735632}\n",
      "{'ner': 0.5641459548196509}\n",
      "{'ner': 5.929858087106487}\n",
      "{'ner': 5.930035440797513}\n",
      "{'ner': 1.9734744197837109}\n",
      "{'ner': 2.8778290198710517}\n",
      "{'ner': 3.542651921549348}\n",
      "{'ner': 2.0834164672622437}\n",
      "{'ner': 2.091508355596626}\n",
      "{'ner': 2.091582593280723}\n",
      "{'ner': 1.7997503294488295}\n",
      "{'ner': 1.815045330750255}\n",
      "{'ner': 1.8150564647630711}\n",
      "{'ner': 0.00014519937734534138}\n",
      "{'ner': 0.0001454606867220751}\n",
      "{'ner': 0.08814021803445551}\n",
      "{'ner': 0.8984906611378818}\n",
      "{'ner': 0.8984998355510535}\n",
      "{'ner': 0.8984999527547031}\n",
      "{'ner': 1.8213121996256806e-07}\n",
      "{'ner': 8.328226501300734e-05}\n",
      "{'ner': 0.001066763180329912}\n",
      "{'ner': 0.06210516575094706}\n",
      "{'ner': 0.06210924662686546}\n",
      "{'ner': 2.7039289902583046}\n",
      "{'ner': 1.9979326396610901}\n",
      "{'ner': 1.9979348642158403}\n",
      "{'ner': 1.9979348839295556}\n",
      "{'ner': 1.9522826489883613}\n",
      "{'ner': 1.9522871377181765}\n",
      "{'ner': 1.9522871533857666}\n",
      "{'ner': 2.2258083663331023}\n",
      "{'ner': 2.2258384342286073}\n",
      "{'ner': 2.2271378308343035}\n",
      "{'ner': 0.00014227243155263936}\n",
      "{'ner': 0.00014229161902418752}\n",
      "{'ner': 0.08388171875291711}\n",
      "{'ner': 3.5971817681314976e-05}\n",
      "{'ner': 0.0002632130228833469}\n",
      "{'ner': 0.0004976930082312021}\n"
     ]
    }
   ],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for batch in minibatch(TRAIN_DATA, size=compounding(4.0, 16.0, 1.001)):\n",
    "            for text, annotations in batch:\n",
    "                #nlp.update(\n",
    "                #    [text],  \n",
    "                #    [annotations],  \n",
    "                #    drop=0.5,  \n",
    "                #    sgd=optimizer,\n",
    "                #    losses=losses)\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], sgd = optimizer, drop=0.4, losses=losses)\n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In bar chart show me last 7 months of loss for product ppr.\r\n",
      "Entities [('bar chart', 'CHART'), ('last 7 months', 'TIME'), ('product ppr', 'PRODUCT')]\n",
      "Show me last 4 months sale of product pqr as bar chart.\r\n",
      "Entities [('last 4 months', 'TIME'), ('product pqr', 'CHART'), ('bar chart', 'CHART')]\n",
      "show me in violin chart the last 22 months of expenditure for product ppz\r\n",
      "Entities [('violin chart', 'CHART'), ('last 22 months', 'TIME'), ('product ppz', 'PRODUCT')]\n",
      "provide me product xyz orders in last 3 months in bar chart format \r\n",
      "Entities [('product xyz', 'PRODUCT'), ('last 3 months', 'TIME'), ('bar chart', 'CHART')]\n",
      "For last 56 months get me in pie chart sales of product aab\n",
      "Entities [('last 56 months', 'TIME'), ('pie chart', 'CHART'), ('product aab', 'PRODUCT')]\n",
      "get me product lmno sales for last 18 months in violin chart\r\n",
      "Entities [('product lmno', 'PRODUCT'), ('last 18 months', 'TIME'), ('violin chart', 'CHART')]\n",
      "provide for product lmp in pie chart last 6 months of sales\r\n",
      "Entities [('product lmp', 'PRODUCT'), ('pie chart', 'CHART'), ('last 6 months', 'TIME')]\n",
      "give product abc sales for last 8 months in bar chart\r\n",
      "Entities [('product abc', 'PRODUCT'), ('last 8 months', 'TIME'), ('bar chart', 'CHART')]\n",
      "present me last 2 months of revenue in pie chart for product zzk\r\n",
      "Entities [('last 2 months', 'TIME'), ('pie chart', 'CHART'), ('product zzk', 'PRODUCT')]\n",
      "get me in bar chart last 10 monthes of sales for product omc\r\n",
      "Entities [('bar chart', 'CHART'), ('last 10 monthes', 'TIME'), ('product omc', 'PRODUCT')]\n"
     ]
    }
   ],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    print(text)\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='product zzorq sales in ham chart for last 36 months '\n",
    "#text='give sale of xyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('product zzorq', 'PRODUCT'), ('ham chart', 'CHART'), ('last 36 months', 'TIME')]\n"
     ]
    }
   ],
   "source": [
    "print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product zzorq sales in ham chart for last 36 months "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product zzorq sales in ham chart for last 36 months '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(product zzorq, ham chart, last 36 months)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir= dataiku.Folder(\"saves\")\n",
    "out_dir_info = out_dir.get_info()\n",
    "out_dir_path=saves_info['path']+'/first_test_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(out_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.8\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'import': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named spacy\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config saves_path config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "command=\"python -m spacy init fill-config saves_path out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'python 3+2' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-dcdde2971b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 438\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'python 3+2' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "subprocess.run(command,shell=True,check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spacy.cli.download import download\n",
    "from spacy.cli.init_config import fill_config\n",
    "from spacy.cli.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-036e93d6b137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfill_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaves_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/cli/init_config.py\u001b[0m in \u001b[0;36mfill_config\u001b[0;34m(output_file, base_path, pretraining, diff, silent)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mshow_validation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhint_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Load a second time with validation to be extra sure that the produced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# config result is a valid config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mauto_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_fill\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m     )\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1850\u001b[0m                         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe_cfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m                         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m                         \u001b[0mraw_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m                     )\n\u001b[1;32m   1854\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mraw_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             )\n\u001b[1;32m    821\u001b[0m         \u001b[0mpipe_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_pipe_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/dataiku/dss_data/code-envs/python/SentTransform/lib64/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0mlang_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             )\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0mpipe_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_factory_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# This is unideal, but the alternative would mean you always need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "fill_config(Path(out_path), Path(saves_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Path(\"config.cfg\"), Path(\"my_model\"), overrides={\"paths.train\": \"train.spacy\", \"paths.dev\": \"dev.spacy\"})"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1699504295125,
  "creator": "arnab.basak",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (env SentTransform)",
   "language": "python",
   "name": "py-dku-venv-senttransform"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "modifiedBy": "arnab.basak",
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
